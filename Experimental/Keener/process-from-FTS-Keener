# Licensed by aoanla under https://creativecommons.org/licenses/by-nc-sa/4.0/
import parse_fts_csv as pfc
import time
import numpy
import networkx
import matplotlib.pyplot as plt
#or use matplotlib's implementation: http://matplotlib.org/api/mlab_api.html#matplotlib.mlab.PCA
#import princomp as pcpa
import sklearn.decomposition as deco
###parameters
##date limits

datelim = time.mktime(time.strptime("06 May 16", "%d %b %y"))   #end of sample training secords
datestart = datelim - 8*28*24*60*60 # 9 months = time for largest stable group to form / minimum number of total connected groups to be reached with this dataset

datetest = datelim + 60*60*24*1 #1 month after datelim, end of testing records


##source data
teamfile = "flattrackstats_teams_2016-06-06.csv"
#teamfile = "top40.csv"
boutfile = "flattrackstats_bouts_2016-06-06.csv"
#boutfile = "flattrackstats_bouts_2016-06-06-Champs2015.csv"

###sequencing
##initialisation
teams_in = pfc.import_teams(teamfile)
bouts_in = pfc.import_bouts(boutfile,4) #second parameter is Laplace/Keener perturbation on scores in ratios
print len(bouts_in)
##selection
teams_winnowed = pfc.select_teams(teams_in,genuses=['W'])
(bouts_out,boutgraph,names) = pfc.select_bouts_weighted(bouts_in,teams_winnowed,datestart,datelim,datetest,weight='ratio')

print len(bouts_out[0])

##subgraph selection

#select largest subgraph - we've changed this to return the actual subgraphs!!
subgraphs = pfc.process_subgraphs_2_directed(boutgraph, teams_winnowed)
smax = {}
subgraphs.sort(reverse=True, key = len )

#print subgraphs[0].nodes()
#print '3409' in subgraphs[0].nodes()

# subgraphs[0] is now the dict of the teams in the largest group as id:{name,type etc} dict

# potentially, we don't want the "maximal boutgraph" as got below - we may want to weight edges, merge parallel edges (for example, as weighted sum of logscoreratio by recency)

#for example, this is the adjacency matrix for the maximal subgraph
#adj_matrix = networkx.adjacency_matrix(subgraphs[0])


#(maximal_bouts, maximal_boutgraph, maximal_names) = pfc.select_bouts(bouts_in, subgraphs[0], datestart, datelim, datetest)



def KeenerPCA(G):
	l = G.number_of_nodes()
	n = G.nodes()
	mapping = {i[1]:i[0] for i in zip(range(l),n)}
	working_matrix = numpy.zeros([l,l])
	
	for e in G.edges(data=True):
		working_matrix[mapping[e[0]]][mapping[e[1]]] += e[2]['weight']
		working_matrix[mapping[e[1]]][mapping[e[0]]] -= e[2]['weight']
	
	pca = deco.PCA(0.95)
	x_r = pca.fit_transform(working_matrix)
	print "Explained variance Ratio:"
	print pca.explained_variance_ratio_
	return x_r.T

scores = KeenerPCA(subgraphs[0])

#for i in range(len(scores)):
#	min_p = min(scores[i])
#	scores[i] -= min_p

scores[0] -= min(scores[0])

names_out = [teams_winnowed[n][0] for n in subgraphs[0].nodes()]
ordering = sorted(zip(names_out,scores[0]),key= lambda x: x[1])

#quit() #skip detailed output

def printer(x):
	print x

print "PCA 1"
[ printer(o) for o in ordering ]

#print "PCA 2"
#[ printer(o) for o in sorted(zip(names_out,scores[1]), key = lambda x:x[1]) ]
#do PCA, or build spring-simulation

print "PCA len(1,2,3)"
score123 = numpy.sqrt(scores[0]**2 + scores[1]**2 + scores[2]**2)
[ printer(o) for o in sorted(zip(names_out,score123), key = lambda x:x[1]) ]

def print_graph_pca(G,pca,text,c):
	limits = [0,0]
	x = 0
	for i in c:
		#and centre
		limits[x] = max(pca[i])
		x += 1
        plt.figure(1,limits)
        node_labels = dict([ (n,teams_winnowed[n][0]) for n in G.nodes() ])
        #node_cols = [ colour_map[teams_winnowed[n][1]] for n in G.nodes() ]
        pos = { n[0]:(n[1][c[0]],n[1][c[1]]) for n in zip(G.nodes(),pca.T) }
	print pos
        networkx.draw_networkx_nodes(G,pos)

        networkx.draw_networkx_edges(G,pos)
        networkx.draw_networkx_labels(G,pos,labels = node_labels)
#        networkx.draw_spring(g,with_labels=True, node_color=node_cols, labels = node_labels)
        plt.savefig(text+str(c[0])+str(c[1])+".png")
        plt.close()


def print_projections(x,y):
	print_graph_pca(subgraphs[0],scores,"pca-test",(x,y))

print_projections(0,1)
print_projections(0,2)
print_projections(1,2)

#we guess that score[0], as the principal component, might be a ranking?
## (we can try the first few principal components to see what they look like)


##output the linear regression stuff
#pfc.write_names(subgraphs[0],maximal_names)
#pfc.output_matrices(maximal_bouts,maximal_names)

